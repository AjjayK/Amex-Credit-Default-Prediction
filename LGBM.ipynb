{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AjjayK/Amex-Credit-Default-Prediction/blob/main/LGBM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#American Express &ndash; Default Prediction\n",
        "<p style='margin-top:0cm;margin-right:0cm;margin-bottom:8.0pt;margin-left:-20.45pt;line-height:107%;font-size:15px;font-family:\"Calibri\",sans-serif;text-indent:41.75pt;'><span style='font-family:\"Open Sans\",sans-serif;'>Predict if a customer will default in the future</span></p>\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "<p style='margin-top:0cm;margin-right:0cm;margin-bottom:8.0pt;margin-left:21.3pt;line-height:107%;font-size:15px;font-family:\"Calibri\",sans-serif;'><strong><span style='font-size:19px;line-height:107%;font-family:\"Open Sans\",sans-serif;'>About Notebook</span></strong></p>\n",
        "<p style='margin-top:0cm;margin-right:0cm;margin-bottom:8.0pt;margin-left:21.3pt;line-height:107%;font-size:15px;font-family:\"Calibri\",sans-serif;'><span style='font-size:16px;line-height:107%;font-family:\"Open Sans\",sans-serif;'>This notebook is an extension to the previous notebook which deals with EDA and deep learning models to predict credit default. This notebook features LGBM model. This notebook requires Python 3.9 with latest LGBM library.</span></p>"
      ],
      "metadata": {
        "id": "ZoyNzk2pxtjJ"
      },
      "id": "ZoyNzk2pxtjJ"
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Initializing the notebook**\n",
        "The notebook does not run on Google Colab since Google Colab uses Python 3.7 and it doesn't support LGBM log_evaluation"
      ],
      "metadata": {
        "id": "1nOTobMByy3u"
      },
      "id": "1nOTobMByy3u"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e77d3af",
      "metadata": {
        "id": "0e77d3af"
      },
      "outputs": [],
      "source": [
        "#Importing the libraries used in this notebook\n",
        "import numpy as np \n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import StratifiedKFold \n",
        "from sklearn.metrics import roc_auc_score, roc_curve, auc\n",
        "from lightgbm import LGBMClassifier, early_stopping, log_evaluation\n",
        "import warnings, gc\n",
        "warnings.filterwarnings(\"ignore\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Loading the Dataset**\n",
        "Dataset was downloaded from Kaggle and is saved in local machine. Enter the directory where dataset is saved."
      ],
      "metadata": {
        "id": "XHLbDcsVzUOb"
      },
      "id": "XHLbDcsVzUOb"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "00affb54",
      "metadata": {
        "id": "00affb54"
      },
      "outputs": [],
      "source": [
        "#Loading the training data\n",
        "train_data = pd.read_feather(input_directory)\n",
        "train_data = train_data.groupby('customer_ID').tail(1).set_index('customer_ID')\n",
        "\n",
        "test_data = pd.read_feather(r\"C:\\Users\\ajjay\\Amex Kaggle\\test_data.ftr\\test_data.ftr\")\n",
        "test_data = test_data.groupby('customer_ID').tail(1).set_index('customer_ID')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "399fd709",
      "metadata": {
        "id": "399fd709"
      },
      "outputs": [],
      "source": [
        "#Column stratification\n",
        "col = train_data.columns.to_list()\n",
        "cat_features = ['B_30', 'B_38', 'D_114', 'D_116', 'D_117', 'D_120', 'D_126', 'D_63', 'D_64', 'D_66', 'D_68']\n",
        "non_cat_features = [x for x in col if x not in cat_features]\n",
        "\n",
        "delinquency_variables = [i for i in col if i.startswith('D_')]\n",
        "spend_variables = [i for i in col if (i.startswith('S_') and i != 'S_2')]\n",
        "payment_variables = [i for i in col if i.startswith('P_')]\n",
        "balance_variables = [i for i in col if i.startswith('B_')]\n",
        "risk_variables = [i for i in col if i.startswith('R_')]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "86bf136a",
      "metadata": {
        "id": "86bf136a",
        "outputId": "0ac8d231-19b8-477b-b20b-1642eaebf677"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "77"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "del train_data['S_2']\n",
        "gc.collect()\n",
        "del test_data['S_2']\n",
        "gc.collect()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Light Gradient Boosting Machine\n",
        "LightGBM is a gradient boosting framework based on decision trees to increases the efficiency of the model and reduces memory usage. \n",
        "It uses two novel techniques: Gradient-based One Side Sampling and Exclusive Feature Bundling (EFB) which fulfills the limitations of histogram-based algorithm that is primarily used in all GBDT (Gradient Boosting Decision Tree) frameworks. The two techniques of GOSS and EFB described below form the characteristics of LightGBM Algorithm. They comprise together to make the model work efficiently and provide it a cutting edge over other GBDT frameworks "
      ],
      "metadata": {
        "id": "sC0melrBzzyi"
      },
      "id": "sC0melrBzzyi"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7a216c44",
      "metadata": {
        "id": "7a216c44",
        "outputId": "d79c532a-69e5-40bb-ecad-83e174ae4947"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Fold 1\n",
            "Train shape: (413021, 188), (413021,), Valid shape: (45892, 188), (45892,)\n",
            "\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[500]\ttraining's auc: 0.971327\ttraining's binary_logloss: 0.191196\tvalid_1's auc: 0.959852\tvalid_1's binary_logloss: 0.221868\n",
            "Early stopping, best iteration is:\n",
            "[559]\ttraining's auc: 0.97245\ttraining's binary_logloss: 0.188027\tvalid_1's auc: 0.959899\tvalid_1's binary_logloss: 0.221776\n",
            "Validation Gini: 0.78717, AUC: 0.9599\n",
            "\n",
            "Fold 2\n",
            "Train shape: (413021, 188), (413021,), Valid shape: (45892, 188), (45892,)\n",
            "\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[500]\ttraining's auc: 0.971298\ttraining's binary_logloss: 0.191223\tvalid_1's auc: 0.959829\tvalid_1's binary_logloss: 0.222303\n",
            "Early stopping, best iteration is:\n",
            "[530]\ttraining's auc: 0.971893\ttraining's binary_logloss: 0.189559\tvalid_1's auc: 0.959853\tvalid_1's binary_logloss: 0.222244\n",
            "Validation Gini: 0.78309, AUC: 0.9599\n",
            "\n",
            "Fold 3\n",
            "Train shape: (413021, 188), (413021,), Valid shape: (45892, 188), (45892,)\n",
            "\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[500]\ttraining's auc: 0.971342\ttraining's binary_logloss: 0.19109\tvalid_1's auc: 0.959387\tvalid_1's binary_logloss: 0.223591\n",
            "Early stopping, best iteration is:\n",
            "[585]\ttraining's auc: 0.972948\ttraining's binary_logloss: 0.186547\tvalid_1's auc: 0.959481\tvalid_1's binary_logloss: 0.223345\n",
            "Validation Gini: 0.78335, AUC: 0.9595\n",
            "\n",
            "Fold 4\n",
            "Train shape: (413022, 188), (413022,), Valid shape: (45891, 188), (45891,)\n",
            "\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[500]\ttraining's auc: 0.971193\ttraining's binary_logloss: 0.191554\tvalid_1's auc: 0.960997\tvalid_1's binary_logloss: 0.219034\n",
            "Early stopping, best iteration is:\n",
            "[692]\ttraining's auc: 0.974725\ttraining's binary_logloss: 0.181542\tvalid_1's auc: 0.96104\tvalid_1's binary_logloss: 0.218887\n",
            "Validation Gini: 0.79070, AUC: 0.9610\n",
            "\n",
            "Fold 5\n",
            "Train shape: (413022, 188), (413022,), Valid shape: (45891, 188), (45891,)\n",
            "\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[500]\ttraining's auc: 0.971236\ttraining's binary_logloss: 0.191407\tvalid_1's auc: 0.960588\tvalid_1's binary_logloss: 0.220451\n",
            "[1000]\ttraining's auc: 0.97971\ttraining's binary_logloss: 0.166859\tvalid_1's auc: 0.960736\tvalid_1's binary_logloss: 0.220126\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1000]\ttraining's auc: 0.97971\ttraining's binary_logloss: 0.166859\tvalid_1's auc: 0.960736\tvalid_1's binary_logloss: 0.220126\n",
            "Validation Gini: 0.78905, AUC: 0.9607\n",
            "\n",
            "Fold 6\n",
            "Train shape: (413022, 188), (413022,), Valid shape: (45891, 188), (45891,)\n",
            "\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[500]\ttraining's auc: 0.971255\ttraining's binary_logloss: 0.191375\tvalid_1's auc: 0.960002\tvalid_1's binary_logloss: 0.221773\n",
            "Early stopping, best iteration is:\n",
            "[484]\ttraining's auc: 0.970942\ttraining's binary_logloss: 0.192244\tvalid_1's auc: 0.960025\tvalid_1's binary_logloss: 0.221727\n",
            "Validation Gini: 0.79083, AUC: 0.9600\n",
            "\n",
            "Fold 7\n",
            "Train shape: (413022, 188), (413022,), Valid shape: (45891, 188), (45891,)\n",
            "\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[500]\ttraining's auc: 0.971391\ttraining's binary_logloss: 0.190958\tvalid_1's auc: 0.958855\tvalid_1's binary_logloss: 0.224869\n",
            "Early stopping, best iteration is:\n",
            "[605]\ttraining's auc: 0.973353\ttraining's binary_logloss: 0.185384\tvalid_1's auc: 0.958893\tvalid_1's binary_logloss: 0.224754\n",
            "Validation Gini: 0.78015, AUC: 0.9589\n",
            "\n",
            "Fold 8\n",
            "Train shape: (413022, 188), (413022,), Valid shape: (45891, 188), (45891,)\n",
            "\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[500]\ttraining's auc: 0.971199\ttraining's binary_logloss: 0.191584\tvalid_1's auc: 0.960533\tvalid_1's binary_logloss: 0.220155\n",
            "Early stopping, best iteration is:\n",
            "[465]\ttraining's auc: 0.970499\ttraining's binary_logloss: 0.193547\tvalid_1's auc: 0.960554\tvalid_1's binary_logloss: 0.220096\n",
            "Validation Gini: 0.78880, AUC: 0.9606\n",
            "\n",
            "Fold 9\n",
            "Train shape: (413022, 188), (413022,), Valid shape: (45891, 188), (45891,)\n",
            "\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[500]\ttraining's auc: 0.971188\ttraining's binary_logloss: 0.191594\tvalid_1's auc: 0.96113\tvalid_1's binary_logloss: 0.218936\n",
            "Early stopping, best iteration is:\n",
            "[681]\ttraining's auc: 0.974531\ttraining's binary_logloss: 0.182098\tvalid_1's auc: 0.961203\tvalid_1's binary_logloss: 0.218718\n",
            "Validation Gini: 0.79226, AUC: 0.9612\n",
            "\n",
            "Fold 10\n",
            "Train shape: (413022, 188), (413022,), Valid shape: (45891, 188), (45891,)\n",
            "\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[500]\ttraining's auc: 0.971248\ttraining's binary_logloss: 0.191475\tvalid_1's auc: 0.960991\tvalid_1's binary_logloss: 0.21925\n",
            "[1000]\ttraining's auc: 0.979716\ttraining's binary_logloss: 0.166873\tvalid_1's auc: 0.961053\tvalid_1's binary_logloss: 0.219024\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1000]\ttraining's auc: 0.979716\ttraining's binary_logloss: 0.166873\tvalid_1's auc: 0.961053\tvalid_1's binary_logloss: 0.219024\n",
            "Validation Gini: 0.79051, AUC: 0.9611\n"
          ]
        }
      ],
      "source": [
        "#LGBM\n",
        "enc = LabelEncoder()\n",
        "for col in cat_features:\n",
        "    train_data[col] = enc.fit_transform(train_data[col])\n",
        "    test_data[col] = enc.transform(test_data[col])\n",
        "\n",
        "X=train_data.drop(['target'],axis=1)\n",
        "y=train_data['target']\n",
        "y_valid, gbm_val_probs, gbm_test_preds, gini=[],[],[],[]\n",
        "ft_importance=pd.DataFrame(index=X.columns)\n",
        "sk_fold = StratifiedKFold(n_splits=10, shuffle=True, random_state=21)\n",
        "for fold, (train_idx, val_idx) in enumerate(sk_fold.split(X, y)):\n",
        "    \n",
        "    print(\"\\nFold {}\".format(fold+1))\n",
        "    X_train, y_train = X.iloc[train_idx,:], y[train_idx]\n",
        "    X_val, y_val = X.iloc[val_idx,:], y[val_idx]\n",
        "    print(\"Train shape: {}, {}, Valid shape: {}, {}\\n\".format(\n",
        "        X_train.shape, y_train.shape, X_val.shape, y_val.shape))\n",
        "    \n",
        "    params = {'boosting_type': 'gbdt',\n",
        "              'n_estimators': 1000,\n",
        "              'num_leaves': 50,\n",
        "              'learning_rate': 0.05,\n",
        "              'colsample_bytree': 0.9,\n",
        "              'min_child_samples': 2000,\n",
        "              'max_bins': 500,\n",
        "              'reg_alpha': 2,\n",
        "              'objective': 'binary',\n",
        "              'random_state': 21}\n",
        "    \n",
        "    gbm = LGBMClassifier(**params).fit(X_train, y_train, \n",
        "                                       eval_set=[(X_train, y_train), (X_val, y_val)],\n",
        "                                       callbacks=[early_stopping(200), log_evaluation(500)],\n",
        "                                       eval_metric=['auc','binary_logloss'])\n",
        "    gbm_prob = gbm.predict_proba(X_val)[:,1]\n",
        "    gbm_val_probs.append(gbm_prob)\n",
        "    y_valid.append(y_val)\n",
        "    \n",
        "    y_pred=pd.DataFrame(data={'prediction':gbm_prob})\n",
        "    y_true=pd.DataFrame(data={'target':y_val.reset_index(drop=True)})\n",
        "    gini_score=amex_metric(y_true = y_true, y_pred = y_pred)\n",
        "    gini.append(gini_score)\n",
        "    \n",
        "    auc_score=roc_auc_score(y_val, gbm_prob)\n",
        "    gbm_test_preds.append(gbm.predict_proba(test_data)[:,1])    \n",
        "    ft_importance[\"Importance_Fold\"+str(fold)]=gbm.feature_importances_    \n",
        "    print(\"Validation Gini: {:.5f}, AUC: {:.4f}\".format(gini_score,auc_score))\n",
        "    \n",
        "    del X_train, y_train, X_val, y_val\n",
        "    _ = gc.collect()\n",
        "    \n",
        "del X, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f80ef9cb",
      "metadata": {
        "id": "f80ef9cb"
      },
      "outputs": [],
      "source": [
        "#Predicting the response using model for training data and test data\n",
        "y_pred = gbm.predict_proba(train_data.loc[:,train_data.columns[0:188]])\n",
        "y_pred_test = gbm.predict_proba(test_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Model Evaluation**\n",
        "#####**Amex Metrics**\n",
        "The evaluation metric, M, for this competition is the mean of two measures of rank ordering: Normalized Gini Coefficient, G, and default rate captured at 4%, D.\n",
        "\n",
        "M=0.5⋅(G+D)\n",
        "The default rate captured at 4% is the percentage of the positive labels (defaults) captured within the highest-ranked 4% of the predictions, and represents a Sensitivity/Recall statistic.\n",
        "\n",
        "For both of the sub-metrics G and D, the negative labels are given a weight of 20 to adjust for downsampling.\n",
        "\n",
        "This metric has a maximum value of 1.0.\n",
        "#####**Sparse Categorical Accuracy**\n",
        "Since interpretation of Amex metrics is difficult, sparse categorical accuracy is estimated for the training data. As 'target' values are not avilable for test data, we only evaluate this metric for training data. It was found that higher the categorical accruacy on training data, higher the Amex metrics on test data. Hence, high value of the categorical accuracy on training data should give a better estimate for higher categorical accuracy for test data."
      ],
      "metadata": {
        "id": "aw5Qx48u1FWY"
      },
      "id": "aw5Qx48u1FWY"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f982dcb6",
      "metadata": {
        "id": "f982dcb6"
      },
      "outputs": [],
      "source": [
        "#Sparse Categorical Accuracy\n",
        "def sparse_categorical_accuracy(y_true, y_pred):\n",
        "  acc = np.dot(1, np.equal(y_true, np.argmax(y_pred, axis=1)))\n",
        "  return (sum(acc)/len(acc))*100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a011de07",
      "metadata": {
        "id": "a011de07"
      },
      "outputs": [],
      "source": [
        "def amex_metric(y_true: pd.DataFrame, y_pred: pd.DataFrame) -> float:\n",
        "\n",
        "    def top_four_percent_captured(y_true: pd.DataFrame, y_pred: pd.DataFrame) -> float:\n",
        "        df = (pd.concat([y_true, y_pred], axis='columns')\n",
        "              .sort_values('prediction', ascending=False))\n",
        "        df['weight'] = df['target'].apply(lambda x: 20 if x==0 else 1)\n",
        "        four_pct_cutoff = int(0.04 * df['weight'].sum())\n",
        "        df['weight_cumsum'] = df['weight'].cumsum()\n",
        "        df_cutoff = df.loc[df['weight_cumsum'] <= four_pct_cutoff]\n",
        "        return (df_cutoff['target'] == 1).sum() / (df['target'] == 1).sum()\n",
        "        \n",
        "    def weighted_gini(y_true: pd.DataFrame, y_pred: pd.DataFrame) -> float:\n",
        "        df = (pd.concat([y_true, y_pred], axis='columns')\n",
        "              .sort_values('prediction', ascending=False))\n",
        "        df['weight'] = df['target'].apply(lambda x: 20 if x==0 else 1)\n",
        "        df['random'] = (df['weight'] / df['weight'].sum()).cumsum()\n",
        "        total_pos = (df['target'] * df['weight']).sum()\n",
        "        df['cum_pos_found'] = (df['target'] * df['weight']).cumsum()\n",
        "        df['lorentz'] = df['cum_pos_found'] / total_pos\n",
        "        df['gini'] = (df['lorentz'] - df['random']) * df['weight']\n",
        "        return df['gini'].sum()\n",
        "\n",
        "    def normalized_weighted_gini(y_true: pd.DataFrame, y_pred: pd.DataFrame) -> float:\n",
        "        y_true_pred = y_true.rename(columns={'target': 'prediction'})\n",
        "        return weighted_gini(y_true, y_pred) / weighted_gini(y_true, y_true_pred)\n",
        "\n",
        "    g = normalized_weighted_gini(y_true, y_pred)\n",
        "    d = top_four_percent_captured(y_true, y_pred)\n",
        "\n",
        "    return 0.5 * (g + d)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "98f26951",
      "metadata": {
        "id": "98f26951",
        "outputId": "e1b3250c-4ccd-4c59-a64e-2032276f39be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sparse categorical accuracy: 92.87599%\n"
          ]
        }
      ],
      "source": [
        "y_true = train_data['target']\n",
        "print(\"Sparse categorical accuracy: {:.5f}%\".format(sparse_categorical_accuracy(y_true,y_pred)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9e8d6316",
      "metadata": {
        "id": "9e8d6316",
        "outputId": "ddceb577-7ed3-43bb-d0c5-c23ca353be65"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Amex metric for deep decision tree model: 0.68132\n"
          ]
        }
      ],
      "source": [
        "print(\"Amex metric for deep decision tree model: {:.5f}\".format(amex_metric(y_true.to_frame(),pd.DataFrame(np.argmax(y_pred, axis=1), columns = ['prediction'], index = train_data.index))))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Test Data Evaluation\n",
        "Using Kaggle API to submit to the competition. Enter your kaggle username and kaggle key"
      ],
      "metadata": {
        "id": "TIWUXcUR7rOP"
      },
      "id": "TIWUXcUR7rOP"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ee2469c",
      "metadata": {
        "id": "7ee2469c"
      },
      "outputs": [],
      "source": [
        "lgbm_out = pd.DataFrame(y_pred_test[:,1], columns = ['prediction'], index = test_data.index)\n",
        "lgbm_out.to_csv('lgbm_out.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "45204700",
      "metadata": {
        "id": "45204700"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['KAGGLE_username'] = username\n",
        "os.environ['KAGGLE_key'] = key\n",
        "import kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "10ffd806",
      "metadata": {
        "id": "10ffd806",
        "outputId": "fcc3c13f-465a-4f2a-aff7-51b0a3088607"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Successfully submitted to American Express - Default Prediction\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0.00/76.1M [00:00<?, ?B/s]\n",
            "  0%|          | 184k/76.1M [00:00<00:43, 1.83MB/s]\n",
            "  2%|1         | 1.38M/76.1M [00:00<00:24, 3.24MB/s]\n",
            "  5%|5         | 4.18M/76.1M [00:00<00:07, 9.78MB/s]\n",
            " 10%|9         | 7.36M/76.1M [00:00<00:04, 16.0MB/s]\n",
            " 12%|#2        | 9.52M/76.1M [00:00<00:03, 17.5MB/s]\n",
            " 15%|#5        | 11.6M/76.1M [00:00<00:04, 16.4MB/s]\n",
            " 18%|#8        | 13.8M/76.1M [00:01<00:03, 18.0MB/s]\n",
            " 21%|##        | 15.7M/76.1M [00:01<00:03, 18.0MB/s]\n",
            " 23%|##3       | 17.6M/76.1M [00:01<00:03, 17.6MB/s]\n",
            " 25%|##5       | 19.4M/76.1M [00:01<00:03, 17.3MB/s]\n",
            " 28%|##8       | 21.5M/76.1M [00:01<00:03, 18.6MB/s]\n",
            " 31%|###       | 23.4M/76.1M [00:01<00:02, 18.8MB/s]\n",
            " 33%|###3      | 25.2M/76.1M [00:01<00:02, 18.5MB/s]\n",
            " 35%|###5      | 27.0M/76.1M [00:01<00:02, 18.1MB/s]\n",
            " 38%|###7      | 28.8M/76.1M [00:01<00:02, 18.1MB/s]\n",
            " 40%|####      | 30.6M/76.1M [00:01<00:02, 18.2MB/s]\n",
            " 43%|####2     | 32.5M/76.1M [00:02<00:02, 18.5MB/s]\n",
            " 45%|####4     | 34.3M/76.1M [00:02<00:02, 18.3MB/s]\n",
            " 47%|####7     | 36.1M/76.1M [00:02<00:02, 18.7MB/s]\n",
            " 50%|####9     | 38.0M/76.1M [00:02<00:02, 18.4MB/s]\n",
            " 52%|#####2    | 39.8M/76.1M [00:02<00:02, 15.1MB/s]\n",
            " 56%|#####5    | 42.6M/76.1M [00:02<00:01, 18.7MB/s]\n",
            " 59%|#####8    | 44.8M/76.1M [00:02<00:01, 19.8MB/s]\n",
            " 61%|######1   | 46.8M/76.1M [00:02<00:01, 19.2MB/s]\n",
            " 64%|######3   | 48.7M/76.1M [00:03<00:01, 19.5MB/s]\n",
            " 67%|######6   | 50.6M/76.1M [00:03<00:01, 18.9MB/s]\n",
            " 69%|######8   | 52.5M/76.1M [00:03<00:01, 18.9MB/s]\n",
            " 71%|#######1  | 54.3M/76.1M [00:03<00:01, 18.9MB/s]\n",
            " 74%|#######3  | 56.2M/76.1M [00:03<00:01, 18.5MB/s]\n",
            " 76%|#######6  | 57.9M/76.1M [00:03<00:01, 17.2MB/s]\n",
            " 79%|#######9  | 60.4M/76.1M [00:03<00:00, 19.4MB/s]\n",
            " 82%|########1 | 62.3M/76.1M [00:03<00:00, 17.5MB/s]\n",
            " 84%|########4 | 64.0M/76.1M [00:03<00:00, 14.9MB/s]\n",
            " 89%|########8 | 67.4M/76.1M [00:04<00:00, 19.7MB/s]\n",
            " 91%|#########1| 69.5M/76.1M [00:04<00:00, 19.0MB/s]\n",
            " 94%|#########3| 71.4M/76.1M [00:04<00:00, 18.1MB/s]\n",
            " 96%|#########6| 73.2M/76.1M [00:04<00:00, 16.9MB/s]\n",
            " 98%|#########8| 74.9M/76.1M [00:04<00:00, 16.8MB/s]\n",
            "100%|##########| 76.1M/76.1M [00:05<00:00, 14.9MB/s]\n"
          ]
        }
      ],
      "source": [
        "!kaggle competitions submit -c amex-default-prediction -f \"C:\\Users\\ajjay\\Amex Kaggle\\lgbm_out.csv\" -m lgbm"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Conclusion**\n",
        "\n",
        "1.   LGBM (Model in other notebook) stands out to be better in terms of metrics (Score - 0.79546 and Categorical Accuracy on training data - 92.87%)\n",
        "2.   Amex Metric for Deep Decision Forest Model was better than Deep Neural Decision Tree since Forest Model is an ensemble model\n",
        "\n",
        "Overall results are given in the table below\n",
        "\n",
        "<table style=\"margin-left:21.3pt;border-collapse:collapse;border:none;\">\n",
        "    <tbody>\n",
        "        <tr>\n",
        "            <td style=\"width: 134.85pt;border: 1pt solid windowtext;padding: 0cm 5.4pt;vertical-align: top;\">\n",
        "                <p style='margin-top:0cm;margin-right:0cm;margin-bottom:0cm;margin-left:0cm;line-height:normal;font-size:15px;font-family:\"Calibri\",sans-serif;'><strong><span style='font-size:16px;font-family:\"Open Sans\",sans-serif;'>Model</span></strong></p>\n",
        "            </td>\n",
        "            <td style=\"width: 134.85pt;border-top: 1pt solid windowtext;border-right: 1pt solid windowtext;border-bottom: 1pt solid windowtext;border-image: initial;border-left: none;padding: 0cm 5.4pt;vertical-align: top;\">\n",
        "                <p style='margin-top:0cm;margin-right:0cm;margin-bottom:0cm;margin-left:0cm;line-height:normal;font-size:15px;font-family:\"Calibri\",sans-serif;'><strong><span style='font-size:16px;font-family:\"Open Sans\",sans-serif;'>Categorical Accuracy on Training Data</span></strong></p>\n",
        "            </td>\n",
        "            <td style=\"width: 134.9pt;border-top: 1pt solid windowtext;border-right: 1pt solid windowtext;border-bottom: 1pt solid windowtext;border-image: initial;border-left: none;padding: 0cm 5.4pt;vertical-align: top;\">\n",
        "                <p style='margin-top:0cm;margin-right:0cm;margin-bottom:0cm;margin-left:0cm;line-height:normal;font-size:15px;font-family:\"Calibri\",sans-serif;'><strong><span style='font-size:16px;font-family:\"Open Sans\",sans-serif;'>Amex Metric on Training Data</span></strong></p>\n",
        "            </td>\n",
        "            <td style=\"width: 134.9pt;border-top: 1pt solid windowtext;border-right: 1pt solid windowtext;border-bottom: 1pt solid windowtext;border-image: initial;border-left: none;padding: 0cm 5.4pt;vertical-align: top;\">\n",
        "                <p style='margin-top:0cm;margin-right:0cm;margin-bottom:0cm;margin-left:0cm;line-height:normal;font-size:15px;font-family:\"Calibri\",sans-serif;'><strong><span style='font-size:16px;font-family:\"Open Sans\",sans-serif;'>Amex Metric on Test Data</span></strong></p>\n",
        "            </td>\n",
        "        </tr>\n",
        "        <tr>\n",
        "            <td style=\"width: 134.85pt;border-right: 1pt solid windowtext;border-bottom: 1pt solid windowtext;border-left: 1pt solid windowtext;border-image: initial;border-top: none;padding: 0cm 5.4pt;vertical-align: top;\">\n",
        "                <p style='margin-top:0cm;margin-right:0cm;margin-bottom:0cm;margin-left:0cm;line-height:normal;font-size:15px;font-family:\"Calibri\",sans-serif;'><span style='font-size:16px;font-family:\"Open Sans\",sans-serif;'>LGBM</span></p>\n",
        "            </td>\n",
        "            <td style=\"width: 134.85pt;border-top: none;border-left: none;border-bottom: 1pt solid windowtext;border-right: 1pt solid windowtext;padding: 0cm 5.4pt;vertical-align: top;\">\n",
        "                <p style='margin-top:0cm;margin-right:0cm;margin-bottom:0cm;margin-left:0cm;line-height:normal;font-size:15px;font-family:\"Calibri\",sans-serif;text-align:center;'><span style='font-size:16px;font-family:\"Open Sans\",sans-serif;'>92.8759%</span></p>\n",
        "            </td>\n",
        "            <td style=\"width: 134.9pt;border-top: none;border-left: none;border-bottom: 1pt solid windowtext;border-right: 1pt solid windowtext;padding: 0cm 5.4pt;vertical-align: top;\">\n",
        "                <p style='margin-top:0cm;margin-right:0cm;margin-bottom:0cm;margin-left:0cm;line-height:normal;font-size:15px;font-family:\"Calibri\",sans-serif;text-align:center;'><span style='font-size:16px;font-family:\"Open Sans\",sans-serif;'>0.6813</span></p>\n",
        "            </td>\n",
        "            <td style=\"width: 134.9pt;border-top: none;border-left: none;border-bottom: 1pt solid windowtext;border-right: 1pt solid windowtext;padding: 0cm 5.4pt;vertical-align: top;\">\n",
        "                <p style='margin-top:0cm;margin-right:0cm;margin-bottom:0cm;margin-left:0cm;line-height:normal;font-size:15px;font-family:\"Calibri\",sans-serif;text-align:center;'><span style='font-size:16px;font-family:\"Open Sans\",sans-serif;'>0.7954</span></p>\n",
        "            </td>\n",
        "        </tr>\n",
        "        <tr>\n",
        "            <td style=\"width: 134.85pt;border-right: 1pt solid windowtext;border-bottom: 1pt solid windowtext;border-left: 1pt solid windowtext;border-image: initial;border-top: none;padding: 0cm 5.4pt;vertical-align: top;\">\n",
        "                <p style='margin-top:0cm;margin-right:0cm;margin-bottom:0cm;margin-left:0cm;line-height:normal;font-size:15px;font-family:\"Calibri\",sans-serif;'><span style='font-size:16px;font-family:\"Open Sans\",sans-serif;'>Deep Neural Decision Tree</span></p>\n",
        "            </td>\n",
        "            <td style=\"width: 134.85pt;border-top: none;border-left: none;border-bottom: 1pt solid windowtext;border-right: 1pt solid windowtext;padding: 0cm 5.4pt;vertical-align: top;\">\n",
        "                <p style='margin-top:0cm;margin-right:0cm;margin-bottom:0cm;margin-left:0cm;line-height:normal;font-size:15px;font-family:\"Calibri\",sans-serif;text-align:center;'><span style='font-size:16px;font-family:\"Open Sans\",sans-serif;'>90.4552%</span></p>\n",
        "            </td>\n",
        "            <td style=\"width: 134.9pt;border-top: none;border-left: none;border-bottom: 1pt solid windowtext;border-right: 1pt solid windowtext;padding: 0cm 5.4pt;vertical-align: top;\">\n",
        "                <p style='margin-top:0cm;margin-right:0cm;margin-bottom:0cm;margin-left:0cm;line-height:normal;font-size:15px;font-family:\"Calibri\",sans-serif;text-align:center;'><span style='font-size:16px;font-family:\"Open Sans\",sans-serif;'>0.7907</span></p>\n",
        "            </td>\n",
        "            <td style=\"width: 134.9pt;border-top: none;border-left: none;border-bottom: 1pt solid windowtext;border-right: 1pt solid windowtext;padding: 0cm 5.4pt;vertical-align: top;\">\n",
        "                <p style='margin-top:0cm;margin-right:0cm;margin-bottom:0cm;margin-left:0cm;line-height:normal;font-size:15px;font-family:\"Calibri\",sans-serif;text-align:center;'><span style='font-size:16px;font-family:\"Open Sans\",sans-serif;'>0.7818</span></p>\n",
        "            </td>\n",
        "        </tr>\n",
        "        <tr>\n",
        "            <td style=\"width: 134.85pt;border-right: 1pt solid windowtext;border-bottom: 1pt solid windowtext;border-left: 1pt solid windowtext;border-image: initial;border-top: none;padding: 0cm 5.4pt;vertical-align: top;\">\n",
        "                <p style='margin-top:0cm;margin-right:0cm;margin-bottom:0cm;margin-left:0cm;line-height:normal;font-size:15px;font-family:\"Calibri\",sans-serif;'><span style='font-size:16px;font-family:\"Open Sans\",sans-serif;'>Deep Neural Decision Forest</span></p>\n",
        "            </td>\n",
        "            <td style=\"width: 134.85pt;border-top: none;border-left: none;border-bottom: 1pt solid windowtext;border-right: 1pt solid windowtext;padding: 0cm 5.4pt;vertical-align: top;\">\n",
        "                <p style='margin-top:0cm;margin-right:0cm;margin-bottom:0cm;margin-left:0cm;line-height:normal;font-size:15px;font-family:\"Calibri\",sans-serif;text-align:center;'><span style='font-size:16px;font-family:\"Open Sans\",sans-serif;'>90.5866%</span></p>\n",
        "            </td>\n",
        "            <td style=\"width: 134.9pt;border-top: none;border-left: none;border-bottom: 1pt solid windowtext;border-right: 1pt solid windowtext;padding: 0cm 5.4pt;vertical-align: top;\">\n",
        "                <p style='margin-top:0cm;margin-right:0cm;margin-bottom:0cm;margin-left:0cm;line-height:normal;font-size:15px;font-family:\"Calibri\",sans-serif;text-align:center;'><span style='font-size:16px;font-family:\"Open Sans\",sans-serif;'>0.8001</span></p>\n",
        "            </td>\n",
        "            <td style=\"width: 134.9pt;border-top: none;border-left: none;border-bottom: 1pt solid windowtext;border-right: 1pt solid windowtext;padding: 0cm 5.4pt;vertical-align: top;\">\n",
        "                <p style='margin-top:0cm;margin-right:0cm;margin-bottom:0cm;margin-left:0cm;line-height:normal;font-size:15px;font-family:\"Calibri\",sans-serif;text-align:center;'><span style='font-size:16px;font-family:\"Open Sans\",sans-serif;'>0.7917</span></p>\n",
        "            </td>\n",
        "        </tr>\n",
        "    </tbody>\n",
        "</table>"
      ],
      "metadata": {
        "id": "ZhcamYoE9NZf"
      },
      "id": "ZhcamYoE9NZf"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}